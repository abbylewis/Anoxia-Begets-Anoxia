---
title: "02 - Temp and DO interpolation"
author: "Abby Lewis"
date: "2023-05-22"
output: html_document
---

This code file interpolates DO and temperature data to a 1m depth resolution, following Jane et al. (2021)

Methods to replicate: 
Impossible values were first removed, which were defined as those less than 0 or greater than 40 for both temperature (degreesCelsius) and DO (milligramsPerLiter). Profiles were removed from further processing if this either removed greater than 95% of a profile or left less than three measurement depths in a profile. Some profiles lacked a 0 depth point. Prior to interpolation, this was added by 1) changing the minimum depth to 0 if it was less than 0.5 m, 2) adding a 0 depth point and assigning temperature and DO values equal to the shallowest available depth if it was greater than 0.5 m but less than or equal to 3 m deep, 3) if the minimum depth exceeded 3 m the profile was excluded from interpolation. Profiles were interpolated from 0 m to the deepest point at 0.5 m intervals using the pchip function of the pracma R package. 

Table of contents for this markdown file:
Step 1: Load packages
Step 2: QAQC
Step 3: Plot the results of QAQC (this is presented as a figure in Appendix S3)
Step 4: Interpolate DO, following Jane et al. (2021) - note that this will take up to 30 min to run all lakes
Step 5: Interpolate temp - note that this will take up to 30 min to run all lakes
Step 6: combine DO and temp


Step 1: Load packages
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(lubridate)
library(pracma)
library(tidyverse)
library(ggpubr)
```


Step 2: QAQC
```{r}
#import data
to_profiles_all <- read.csv("https://pasta-s.lternet.edu/package/data/eml/edi/1029/9/caf59a118a1490e7cb1a219c55b920f9")
to_profiles_all$Date <- as.Date(to_profiles_all$Date)
lat_long <- read.csv("https://pasta-s.lternet.edu/package/data/eml/edi/1029/9/fadd3eaa25b5fdd1fc4efba70e660579") #Metadata

#Remove very shallow lakes
to_profiles <- to_profiles_all%>%
  left_join(lat_long, by = c("LakeID"))%>%
  filter(is.na(MaximumDepth_m)|MaximumDepth_m>6.4)%>%
  rename(reported_max_depth = MaximumDepth_m)

#Take a look at cases where the depth sampled is deeper than the reported max depth of the lake
depth_issues <- to_profiles%>%
  group_by(LakeID,Date)%>%
  mutate(max_depth = max(Depth_m, na.rm = T))%>%
  group_by(LakeID)%>%
  mutate(depth_sd = sd(max_depth,na.rm = T))%>%
  filter(max_depth - reported_max_depth > .2*reported_max_depth,
         max_depth - reported_max_depth > 5)%>%
  dplyr::select(LakeID,max_depth,reported_max_depth,Date,depth_sd)%>%
  unique()

#Remove max depth outliers using IQR
test_depth_removal <- to_profiles%>%
  group_by(LakeID,Date)%>%
  mutate(max_depth = max(Depth_m, na.rm = T))%>%
  group_by(LakeID)%>%
  filter(is.na(max_depth)|max_depth>=2,
         abs(max_depth-reported_max_depth)<0.3*reported_max_depth|abs(max_depth-reported_max_depth)<=2
         )%>%
  group_by(LakeID)%>%
  mutate(outlier = (max_depth<(quantile(max_depth,.25)-1.5*IQR(max_depth))|
                      max_depth>(quantile(max_depth,.75)+1.5*IQR(max_depth)))&
           (max_depth-quantile(max_depth,.5))>5)%>%
  filter(!outlier)

#Some still have fairly large ranges even after outlier removal. HOWEVER these are mostly very deep lakes
range <- test_depth_removal%>%
  group_by(LakeID)%>%
  dplyr::summarize(range = max(max_depth)-min(max_depth))%>%
  left_join(lat_long, by= c("LakeID"="LakeID"))%>%
  mutate(range_frac = range/MaximumDepth_m)%>%
  filter(range>5&range_frac>.3)

#Saving this as our current workflow
to_profiles_depth_checked <- test_depth_removal%>%
  dplyr::select(LakeID,Date,Depth_m,Temp_C,DO_sat,DO_mgL,Flag_Temp_C,Flag_DO_mgL)

nrow(to_profiles)
nrow(to_profiles_depth_checked)
nrow(to_profiles_depth_checked)/nrow(to_profiles) #84% of the data points remain
nrow(to_profiles%>%filter(reported_max_depth>6.4)) #The loss of profiles is not primarily because of shallow lakes

length(unique(to_profiles$LakeID))
unique(to_profiles$LakeID[is.na(to_profiles$reported_max_depth)])
length(unique(to_profiles_depth_checked$LakeID)) #~50 lakes lost entirely. 
#NOTE I looked into this and it is almost entirely from removing lakes without measurements below 3m deep (typically very shallow lakes)
```


Step 3: Plot the results of QAQC (this is presented as a figure in Appendix S3)
```{r}
#Calculate stats for the original dataset (before QAQC)
unclean <- to_profiles%>%
  group_by(Date,LakeID)%>%
  mutate(max_depth = max(Depth_m, na.rm = T))%>%
  group_by(LakeID,Date,reported_max_depth)%>%
  dplyr::summarize(dif = unique(reported_max_depth)-unique(max_depth),
                   max_depth = unique(max_depth))%>%
  group_by(LakeID,reported_max_depth)%>%
  dplyr::summarize(mean_dif = mean(dif,na.rm=T),
                   mean_max = mean(max_depth,na.rm=T),
                   sd_max = sd(max_depth,na.rm = T),
                   pct_sampled = unique(mean_max)/unique(reported_max_depth)*100,
                   sd_pct_sampled = sd(max_depth,na.rm = T)/unique(reported_max_depth)*100)%>%
  ungroup()%>%
  unique()%>%
  filter(pct_sampled<300)%>%
  mutate(n_lakes = length(unique(LakeID)),
         mean_pct_sampled = mean(pct_sampled,na.rm=T),
         median_pct_sampled = median(pct_sampled,na.rm=T),
         mean_sd_max = mean(sd_max,na.rm=T),
         median_sd_max = median(sd_max,na.rm=T))

#Plot
unclean_plot <- unclean%>%
  ggplot(aes(x = reported_max_depth,y=pct_sampled))+
  geom_point(alpha = 0.3, color = "blue")+
  geom_text(aes(x=6.5,y=190,label = paste0(
    "Mean: ",round(unique(mean_pct_sampled),1),"%",
    "\nMedian: ",round(unique(median_pct_sampled),1),"%",
    "\nn: ",unique(n_lakes)," lakes"
  )), hjust = 0, vjust = 1)+
  geom_hline(yintercept=100)+
  theme_bw()+
  scale_x_log10()+
  ggtitle("Before cleaning process")+
  ylab("Mean percent of the\nwater column sampled")+
  ylim(c(min(unclean$pct_sampled),200))+ #allow space for text
  xlab("Reported maximum depth")+
  theme(axis.title.x = element_blank())
unclean_sd <- unclean%>%
  ggplot(aes(x = reported_max_depth,y=sd_max))+
  geom_point(alpha = 0.3, color = "blue")+
  geom_text(aes(x=6.5,y=45,label = paste0(
    "Mean: ",round(unique(mean_sd_max),1),"m",
    "\nMedian: ",round(unique(median_sd_max),1),"m")), hjust = 0, vjust = 1)+
  #geom_hline(yintercept=100)+
  theme_bw()+
  scale_x_log10()+
  ylab("Standard deviation of\nmaximum sampled depth")+
  xlab("Reported maximum depth")

#Calculate stats for the qaqc-ed dataset
clean <- test_depth_removal%>%
  group_by(Date,LakeID)%>%
  mutate(max_depth = max(Depth_m, na.rm = T))%>%
  group_by(LakeID,Date,reported_max_depth)%>%
  dplyr::summarize(dif = unique(reported_max_depth)-unique(max_depth),
                   max_depth = unique(max_depth))%>%
  group_by(LakeID,reported_max_depth)%>%
  dplyr::summarize(mean_dif = mean(dif,na.rm=T),
                   mean_max = mean(max_depth,na.rm=T),
                   sd_max = sd(max_depth,na.rm = T),
                   pct_sampled = unique(mean_max)/unique(reported_max_depth)*100,
                   sd_pct_sampled = sd(max_depth,na.rm = T)/unique(reported_max_depth)*100)%>%
  ungroup()%>%
  unique()%>%
  filter(pct_sampled<300)%>%
  mutate(n_lakes = length(unique(LakeID)),
         mean_pct_sampled = mean(pct_sampled,na.rm=T),
         median_pct_sampled = median(pct_sampled,na.rm=T),
         mean_sd_max = mean(sd_max,na.rm=T),
         median_sd_max = median(sd_max,na.rm=T))

#Plot
clean_plot <- clean%>%
  ggplot(aes(x = reported_max_depth,y=pct_sampled))+
  geom_point(alpha = 0.3, color = "blue")+
  geom_text(aes(x=6.5,y=190,label = paste0(
    "Mean: ",round(unique(mean_pct_sampled),1),"%",
    "\nMedian: ",round(unique(median_pct_sampled),1),"%",
    "\nn: ",unique(n_lakes)," lakes"
  )), hjust = 0, vjust = 1)+
  geom_hline(yintercept=100)+
  ylim(c(min(unclean$pct_sampled),200))+
  xlim(c(min(unclean$reported_max_depth),max(unclean$reported_max_depth)))+
  theme_bw()+
  scale_x_log10()+
  ggtitle("After cleaning process")+
  ylab("Mean percent of the\nwater column sampled")+
  xlab("Reported maximum depth")+
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank())
clean_sd <- clean%>%
  ggplot(aes(x = reported_max_depth,y=sd_max))+
  geom_point(alpha = 0.3, color = "blue")+
  geom_text(aes(x=6.5,y=45,label = paste0(
    "Mean: ",round(unique(mean_sd_max),1),"m",
    "\nMedian: ",round(unique(median_sd_max),1),"m")), hjust = 0, vjust = 1)+
  #geom_hline(yintercept=100)+
  ylim(c(min(unclean$sd_max,na.rm=T),max(unclean$sd_max,na.rm=T)))+
  xlim(c(min(unclean$reported_max_depth),max(unclean$reported_max_depth)))+
  theme_bw()+
  scale_x_log10()+
  ylab("Standard deviation of\nmaximum sampled depth")+
  xlab("Reported maximum depth")+
  theme(axis.title.y = element_blank())

jpeg("../Figures/depth_cleaning_all.jpg",res=300,width=6, height = 5, units = "in")
ggarrange(unclean_plot,clean_plot, unclean_sd, clean_sd, labels = "auto",nrow=2, ncol = 2, align = "v")
dev.off()
```


Step 4: Interpolate DO, following Jane et al. (2021) - note that this will take up to 30 min to run all lakes
```{r}
#Prep for interpolation

#Filter to profiles with at least 3 measurements
to_profiles_cleaning1 <- to_profiles_depth_checked %>%
  filter(!is.na(DO_mgL))%>%
  group_by(LakeID,Date) %>% 
  filter(length(unique(Depth_m)) >2,#less than three measurement depths
         )%>%
  mutate(crit=min(Depth_m)) %>% 
  ungroup()%>%
  filter(crit<=3)#remove profiles where the shallowest value is larger than 3

#take care of all the non-zeros
nozeros<-to_profiles_cleaning1 %>% 
  group_by(LakeID,Date) %>%
  mutate(crit=min(Depth_m)) %>% 
  ungroup()%>%
  filter(crit!=0)

#change anything Depth <0.5 to 0 (remove them first)
nozeros_case1<-nozeros %>% 
  filter(crit<=0.5)%>%
  mutate(Depth_m = ifelse(Depth_m == crit,0,Depth_m))

#add additional 0m measurement for depths between 0.5 and 3
nozeros_case2_zeros<-nozeros %>% 
  filter(crit>0.5) %>% 
  filter(crit<=3) %>%
  ungroup()%>%
  filter(Depth_m==crit)%>%#only take the lowest value
  mutate(Depth_m=0) %>% unique()
nozeros_case2 <- nozeros %>% 
  filter(crit>0.5) %>% 
  filter(crit<=3) %>%
  full_join(nozeros_case2_zeros)


to_profiles_cleaning2 <- to_profiles_cleaning1 %>% 
  filter(crit==0)%>%
  ungroup() %>%
  rbind(nozeros_case1)%>%
  rbind(nozeros_case2) %>% 
  arrange(LakeID,Date,Depth_m)  %>%
  group_by(LakeID,Date) %>% 
  mutate(somany=n_distinct(Depth_m)) %>% 
  ungroup() %>% filter(somany>=2)%>%
  dplyr::select(-somany,-crit)

interp_do <- function(lake,to_profiles_cleaning2){
  message(paste0("Running: ",lake))
  alldates<-to_profiles_cleaning2 %>% dplyr::select(LakeID,Date,Depth_m,DO_mgL) %>%
    filter(LakeID==lake) %>%
    dplyr::select(Date) %>% unique() %>% unlist() %>% as.vector()
  
  lake_data <- to_profiles_cleaning2 %>%
    filter(LakeID==lake)
  
  interpolatedvalues.do <- map_df(alldates,run_all_dates_do,lake_data,lake)
  
  return(interpolatedvalues.do)
}

run_all_dates_do <- function(alldates,lake_data,lake){
  profile <- lake_data %>% filter(Date==alldates)
  
  interpolated.depths <- seq(from=0, to= max(profile$Depth_m))
  
  datamatrix_<- data.frame(
    depths=profile$Depth_m,
    values=profile$DO_mgL)%>%
    group_by(depths) %>% dplyr::summarize(valuemean=mean(values)) %>% ungroup() %>% as.matrix()
  
  interpolated.dos <- pchip(xi= datamatrix_[,1], yi=datamatrix_[,2],x= interpolated.depths  )
  
  output <- data.frame(LakeID=lake,
                      Date=alldates,
                      Depth_m=interpolated.depths,
                      DO_mgL=interpolated.dos)
  return(output)
}
laken <- to_profiles_cleaning2$LakeID %>% unique()

interpolatedvalues.do <- map_df(laken,interp_do,to_profiles_cleaning2)

ploto<-ggplot(interpolatedvalues.do)+
  geom_line(aes(y=DO_mgL,x=-Depth_m,group=Date))+
  facet_wrap(LakeID~.,scales="free")+
  coord_flip()
```


Step 5: Interpolate temp - note that this will take up to 30 min to run all lakes
```{r}
#Prep for interpolation

to_profiles_cleaning1 <- to_profiles_depth_checked %>%
  filter(!is.na(Temp_C))%>%
  group_by(LakeID,Date) %>% 
  filter(length(unique(Depth_m)) >2,#less than three measurement depths
         )%>%
  mutate(crit=min(Depth_m)) %>% 
  ungroup()%>%
  filter(crit<=3)#remove profiles where the lowest value is larger than 3

#take care of all the non-zeros
nozeros<-to_profiles_cleaning1 %>% 
  group_by(LakeID,Date) %>%
  mutate(crit=min(Depth_m)) %>% 
  ungroup()%>%filter(crit!=0)

#change anything Depth <0.5 to 0 (remove them first)
nozeros_case1<-nozeros %>% 
  filter(crit<=0.5)%>%
  mutate(Depth_m = ifelse(Depth_m == crit,0,Depth_m))

#add additional 0m measurement for depths between 0.5 and 3
nozeros_case2_zeros<-nozeros %>% 
  filter(crit>0.5) %>% 
  filter(crit<=3) %>%
  ungroup()%>%
  filter(Depth_m==crit)%>%#only take the lowest value
  mutate(Depth_m=0) %>% unique()
nozeros_case2 = nozeros %>% 
  filter(crit>0.5) %>% 
  filter(crit<=3) %>%
  full_join(nozeros_case2_zeros)

to_profiles_cleaning2 <- to_profiles_cleaning1 %>% 
  filter(crit==0)%>%
  ungroup() %>%
  rbind(nozeros_case1)%>%rbind(nozeros_case2) %>% arrange(LakeID,Date,Depth_m)  %>%
  group_by(LakeID,Date) %>% mutate(somany=n_distinct(Depth_m)) %>% ungroup() %>% filter(somany>=2)%>%dplyr::select(-somany)#less than three measurement depths 


interp_t <- function(lake,to_profiles_cleaning2){
  message(paste0("Running: ",lake))
  alldates<-to_profiles_cleaning2 %>% dplyr::select(LakeID,Date,Depth_m,Temp_C)%>%
    filter(LakeID==lake) %>%
    dplyr::select(Date) %>% unique() %>% unlist() %>% as.vector()
  
  lake_data <- to_profiles_cleaning2 %>%
    filter(LakeID==lake)
  
  interpolatedvalues.do <- map_df(alldates,run_all_dates_t,lake_data,lake)
  
  return(interpolatedvalues.do)
}

run_all_dates_t <- function(alldates,lake_data,lake){
  profile <- lake_data %>% filter(Date==alldates)
  
  interpolated.depths <- seq(from=0, to= max(profile$Depth_m))
  
  datamatrix_<- data.frame(
    depths=profile$Depth_m,
    values=profile$Temp_C)%>%
    group_by(depths) %>% dplyr::summarize(valuemean=mean(values)) %>% ungroup() %>% as.matrix()
  
  interpolated.dos <- pchip(xi= datamatrix_[,1], yi=datamatrix_[,2],x= interpolated.depths  )
  
  output = data.frame(LakeID=lake,
                      Date=alldates,
                      Depth_m=interpolated.depths,
                      Temp_C=interpolated.dos)
  return(output)
}

laken<-to_profiles_cleaning2$LakeID %>% unique()
interpolatedvalues.t <- map_df(laken,interp_t,to_profiles_cleaning2)

plott<-ggplot(interpolatedvalues.t)+
  geom_line(aes(y=Temp_C,x=-Depth_m,group=Date))+
  facet_wrap(LakeID~.,scales="free")+
  coord_flip()
```


Step 6 combine DO and temp
```{r}
database.interp<-full_join(interpolatedvalues.t,interpolatedvalues.do,
          by=c("LakeID","Depth_m","Date"))%>%
  mutate(Date = as.Date(Date, origin = "1970-01-01"))

## export
write.csv(database.interp,"../Compiled data/temp_o2_interpolated.csv")

#number of profiles before and after
#oxygen
to_profiles %>% filter(!is.na(DO_mgL)) %>% group_by(LakeID) %>% dplyr::select(Date)%>% unique() #99535
database.interp %>% filter(!is.na(DO_mgL)) %>% group_by(LakeID) %>% dplyr::select(Date)%>% unique() #82638
#temp
to_profiles %>% filter(!is.na(Temp_C)) %>% group_by(LakeID) %>% dplyr::select(Date)%>% unique() #105481
database.interp %>% filter(!is.na(Temp_C)) %>% group_by(LakeID) %>% dplyr::select(Date)%>% unique() #83503

#look at time
ggplot(database.interp %>% group_by(LakeID,Date)%>%dplyr::summarize(meando=mean(DO_mgL))) +
  geom_point(aes(x=as.Date(Date, origin = "1970-01-01"),y=LakeID,group=LakeID))

ggplot(to_profiles %>% group_by(LakeID,Date)%>%dplyr::summarize(meando=mean(DO_mgL))) +
  geom_point(aes(x=as.Date(Date, origin = "1970-01-01"),y=LakeID,group=LakeID))
```
